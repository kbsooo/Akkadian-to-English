{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7f1dc22",
   "metadata": {},
   "source": [
    "# Akkadian ‚Üí English Translation: Inference (V1)\n",
    "\n",
    "**Environment**: Kaggle T4 GPU x2\n",
    "\n",
    "**Model**: ByT5-base (loaded from Kaggle Models)\n",
    "\n",
    "**Workflow**:\n",
    "1. Load trained model from Kaggle Models/Dataset\n",
    "2. Load test data from competition\n",
    "3. Run inference with batching\n",
    "4. Create submission.csv\n",
    "\n",
    "**Usage (convert to notebook)**:\n",
    "```bash\n",
    "uv run jupytext --to notebook src/akka_v1_infer.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414952db",
   "metadata": {},
   "source": [
    "## 1. Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e236b6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90bf548",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Configuration\n",
    "# =============================\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Inference configuration for Kaggle T4 x2 environment.\"\"\"\n",
    "    # Paths (Kaggle)\n",
    "    kaggle_input: Path = Path(\"/kaggle/input\")\n",
    "    kaggle_working: Path = Path(\"/kaggle/working\")\n",
    "    \n",
    "    # Model settings\n",
    "    # Option 1: Set model dataset name (uploaded as Kaggle Dataset)\n",
    "    model_dataset_name: Optional[str] = None  # e.g., \"akkadian-byt5-v1\"\n",
    "    \n",
    "    # Option 2: Set model path directly\n",
    "    model_path: Optional[Path] = None\n",
    "    \n",
    "    # Inference\n",
    "    max_source_length: int = 256\n",
    "    max_target_length: int = 256\n",
    "    batch_size: int = 8  # larger batch for inference\n",
    "    num_beams: int = 4\n",
    "    \n",
    "    # Hardware\n",
    "    fp16: bool = True  # Use FP16 for faster inference\n",
    "\n",
    "\n",
    "CFG = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5218c03",
   "metadata": {},
   "source": [
    "## 2. Environment Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c178a1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_kaggle() -> bool:\n",
    "    \"\"\"Check if running on Kaggle.\"\"\"\n",
    "    return Path(\"/kaggle/input\").exists()\n",
    "\n",
    "\n",
    "def find_competition_data() -> Path:\n",
    "    \"\"\"Find competition data directory.\"\"\"\n",
    "    if not is_kaggle():\n",
    "        # Local fallback\n",
    "        local_path = Path(\"data\")\n",
    "        if local_path.exists():\n",
    "            return local_path\n",
    "        raise FileNotFoundError(\"Cannot find competition data locally\")\n",
    "    \n",
    "    # On Kaggle: look for test.csv and sample_submission.csv\n",
    "    for d in CFG.kaggle_input.iterdir():\n",
    "        if (d / \"test.csv\").exists() and (d / \"sample_submission.csv\").exists():\n",
    "            return d\n",
    "    raise FileNotFoundError(\"Cannot find competition data in /kaggle/input\")\n",
    "\n",
    "\n",
    "def find_model_dir() -> Path:\n",
    "    \"\"\"Find trained model directory.\"\"\"\n",
    "    # Option 1: Explicit path (handle both str and Path)\n",
    "    if CFG.model_path:\n",
    "        model_path = Path(CFG.model_path) if isinstance(CFG.model_path, str) else CFG.model_path\n",
    "        if model_path.exists():\n",
    "            return model_path\n",
    "    \n",
    "    # Option 2: Dataset name\n",
    "    if CFG.model_dataset_name:\n",
    "        model_path = CFG.kaggle_input / CFG.model_dataset_name\n",
    "        if model_path.exists():\n",
    "            # Check if config.json is in root or subdirectory\n",
    "            if (model_path / \"config.json\").exists():\n",
    "                return model_path\n",
    "            for sub in model_path.glob(\"**/config.json\"):\n",
    "                return sub.parent\n",
    "        raise FileNotFoundError(f\"Model dataset not found: {model_path}\")\n",
    "    \n",
    "    # Option 3: Auto-detect from /kaggle/input\n",
    "    if is_kaggle():\n",
    "        for d in CFG.kaggle_input.iterdir():\n",
    "            if not d.is_dir():\n",
    "                continue\n",
    "            # Skip competition data\n",
    "            if (d / \"test.csv\").exists():\n",
    "                continue\n",
    "            # Check for model files\n",
    "            if (d / \"config.json\").exists():\n",
    "                return d\n",
    "            for sub in d.glob(\"**/config.json\"):\n",
    "                return sub.parent\n",
    "    \n",
    "    # Option 4: Local trained model\n",
    "    local_model = Path(\"outputs/akkadian_v1/final\")\n",
    "    if local_model.exists():\n",
    "        return local_model\n",
    "    \n",
    "    raise FileNotFoundError(\n",
    "        \"Could not find model directory. \"\n",
    "        \"Set CFG.model_dataset_name or CFG.model_path\"\n",
    "    )\n",
    "\n",
    "\n",
    "COMP_DATA_DIR = find_competition_data()\n",
    "MODEL_DIR = find_model_dir()\n",
    "\n",
    "print(f\"üìÅ Competition data: {COMP_DATA_DIR}\")\n",
    "print(f\"ü§ñ Model directory: {MODEL_DIR}\")\n",
    "print(f\"üñ•Ô∏è Running on Kaggle: {is_kaggle()}\")\n",
    "print(f\"üéÆ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU count: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"   GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c328a120",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing (same as training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ba4ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subscript conversion map\n",
    "_SUBSCRIPT_MAP = str.maketrans({\n",
    "    \"\\u2080\": \"0\", \"\\u2081\": \"1\", \"\\u2082\": \"2\", \"\\u2083\": \"3\", \"\\u2084\": \"4\",\n",
    "    \"\\u2085\": \"5\", \"\\u2086\": \"6\", \"\\u2087\": \"7\", \"\\u2088\": \"8\", \"\\u2089\": \"9\",\n",
    "    \"\\u2093\": \"x\",\n",
    "})\n",
    "\n",
    "\n",
    "def normalize_transliteration(text: str) -> str:\n",
    "    \"\"\"Normalize Akkadian transliteration for model input.\n",
    "    \n",
    "    Important: This must match the preprocessing used during training!\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    \n",
    "    # Unicode normalization\n",
    "    text = unicodedata.normalize(\"NFC\", text)\n",
    "    \n",
    "    # Normalize special H character\n",
    "    text = text.replace(\"\\u1E2A\", \"H\").replace(\"\\u1E2B\", \"h\")\n",
    "    \n",
    "    # Convert subscripts to numbers\n",
    "    text = text.translate(_SUBSCRIPT_MAP)\n",
    "    \n",
    "    # Handle gaps and damaged portions\n",
    "    text = text.replace(\"\\u2026\", \" <gap> \")  # ellipsis\n",
    "    text = re.sub(r\"\\.\\.\\.+\", \" <gap> \", text)\n",
    "    text = re.sub(r\"\\[([^\\]]*)\\]\", \" <gap> \", text)  # [damaged text]\n",
    "    \n",
    "    # Handle unknown signs\n",
    "    text = re.sub(r\"\\bx\\b\", \" <unk> \", text)\n",
    "    \n",
    "    # Remove editorial marks\n",
    "    text = re.sub(r\"[!?/]\", \" \", text)\n",
    "    \n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7ac811",
   "metadata": {},
   "source": [
    "## 4. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956b8da7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from transformers import ByT5Tokenizer\n",
    "\n",
    "print(f\"ü§ñ Loading model from {MODEL_DIR}\")\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_DIR)\n",
    "\n",
    "# Force ByT5Tokenizer and compute extra_ids from model config.\n",
    "# ByT5 vocab = 256 bytes + 3 specials + extra_ids => extra_ids = vocab_size - 259\n",
    "vocab_size = getattr(model.config, \"vocab_size\", None)\n",
    "extra_ids = 125\n",
    "if isinstance(vocab_size, int):\n",
    "    extra_ids = max(vocab_size - 259, 0)\n",
    "tokenizer = ByT5Tokenizer(extra_ids=extra_ids)\n",
    "print(f\"   ‚úÖ Using ByT5Tokenizer(extra_ids={extra_ids})\")\n",
    "\n",
    "# Sanity check for potential mismatch\n",
    "if isinstance(vocab_size, int) and tokenizer.vocab_size != vocab_size:\n",
    "    print(\n",
    "        f\"   ‚ö†Ô∏è Tokenizer vocab_size ({tokenizer.vocab_size}) != model vocab_size ({vocab_size})\"\n",
    "    )\n",
    "\n",
    "# Move to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Use FP16 for faster inference\n",
    "if CFG.fp16 and device.type == \"cuda\":\n",
    "    model = model.half()\n",
    "    print(\"   ‚úÖ Using FP16 for inference\")\n",
    "\n",
    "model.eval()\n",
    "print(f\"   ‚úÖ Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9321fc42",
   "metadata": {},
   "source": [
    "## 5. Inference Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2548f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_batch(texts: List[str]) -> List[str]:\n",
    "    \"\"\"Generate translations for a batch of texts.\"\"\"\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(\n",
    "        texts,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=CFG.max_source_length,\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Generate\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_length=CFG.max_target_length,\n",
    "        num_beams=CFG.num_beams,\n",
    "        early_stopping=True,\n",
    "    )\n",
    "    \n",
    "    # Decode\n",
    "    translations = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return translations\n",
    "\n",
    "\n",
    "def translate_all(texts: List[str], batch_size: int = None) -> List[str]:\n",
    "    \"\"\"Translate all texts with batching and progress bar.\"\"\"\n",
    "    if batch_size is None:\n",
    "        batch_size = CFG.batch_size\n",
    "    \n",
    "    all_translations = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Translating\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        translations = generate_batch(batch)\n",
    "        all_translations.extend(translations)\n",
    "    \n",
    "    return all_translations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817e707f",
   "metadata": {},
   "source": [
    "## 6. Load Test Data & Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413ece8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìñ Loading test data...\")\n",
    "test_df = pd.read_csv(COMP_DATA_DIR / \"test.csv\")\n",
    "print(f\"   Test samples: {len(test_df)}\")\n",
    "\n",
    "# Check columns\n",
    "required_cols = {\"id\", \"transliteration\"}\n",
    "if not required_cols.issubset(test_df.columns):\n",
    "    raise ValueError(f\"Test data missing columns: {required_cols - set(test_df.columns)}\")\n",
    "\n",
    "# Normalize input\n",
    "print(\"üîß Normalizing transliterations...\")\n",
    "normalized_texts = [\n",
    "    normalize_transliteration(t) \n",
    "    for t in test_df[\"transliteration\"].tolist()\n",
    "]\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nSample input (normalized):\")\n",
    "for i in range(min(2, len(normalized_texts))):\n",
    "    print(f\"  [{i}] {normalized_texts[i][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db779bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüöÄ Running inference...\")\n",
    "translations = translate_all(normalized_texts)\n",
    "\n",
    "# Show sample outputs\n",
    "print(\"\\nSample outputs:\")\n",
    "for i in range(min(2, len(translations))):\n",
    "    print(f\"  [{i}] {translations[i][:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d863f02",
   "metadata": {},
   "source": [
    "## 7. Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e9fb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"id\": test_df[\"id\"],\n",
    "    \"translation\": translations,\n",
    "})\n",
    "\n",
    "# Validate\n",
    "assert len(submission) == len(test_df), \"Submission length mismatch!\"\n",
    "assert submission[\"translation\"].notna().all(), \"Found NaN translations!\"\n",
    "\n",
    "# Save\n",
    "submission_path = CFG.kaggle_working / \"submission.csv\" if is_kaggle() else Path(\"submission.csv\")\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Submission saved to: {submission_path}\")\n",
    "print(f\"   Total predictions: {len(submission)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f4a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview submission\n",
    "print(\"\\nüìÑ Submission preview:\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed81c69c",
   "metadata": {},
   "source": [
    "## 8. Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c51cfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample submission for comparison\n",
    "sample_sub = pd.read_csv(COMP_DATA_DIR / \"sample_submission.csv\")\n",
    "\n",
    "print(\"\\nüîç Comparison with sample submission:\")\n",
    "print(f\"   Sample submission shape: {sample_sub.shape}\")\n",
    "print(f\"   Our submission shape: {submission.shape}\")\n",
    "\n",
    "# Check if IDs match\n",
    "if set(submission[\"id\"]) == set(sample_sub[\"id\"]):\n",
    "    print(\"   ‚úÖ IDs match!\")\n",
    "else:\n",
    "    print(\"   ‚ùå ID mismatch!\")\n",
    "\n",
    "# Show comparison\n",
    "print(\"\\nüìä Side-by-side comparison (first 2):\")\n",
    "for i in range(min(2, len(submission))):\n",
    "    print(f\"\\n[ID: {submission.iloc[i]['id']}]\")\n",
    "    print(f\"  Sample: {sample_sub.iloc[i]['translation'][:100]}...\")\n",
    "    print(f\"  Ours:   {submission.iloc[i]['translation'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a83917",
   "metadata": {},
   "source": [
    "## 9. Done!\n",
    "\n",
    "Your `submission.csv` is ready for submission to Kaggle.\n",
    "\n",
    "**Next Steps:**\n",
    "1. Click \"Save Version\" in Kaggle\n",
    "2. Go to the competition page\n",
    "3. Submit the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceacd995",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéâ Inference complete!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüìÅ Submission file: {submission_path}\")\n",
    "print(\"\\nTo submit:\")\n",
    "print(\"1. Save this notebook version\")\n",
    "print(\"2. Go to competition page ‚Üí Submit\")\n",
    "print(\"3. Select this notebook's output\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
