{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7350ef0",
   "metadata": {},
   "source": [
    "# Akkadian V2 Training (Colab Version)\n",
    "\n",
    "**Key Changes from V1:**\n",
    "- Unified ASCII normalization (Train/Test style mismatch fixed)\n",
    "- All diacritics converted to ASCII (≈°‚Üís, √†‚Üía, etc.)\n",
    "\n",
    "**Environment**: Google Colab with GPU\n",
    "\n",
    "**Output**: Saved to Google Drive `/content/drive/MyDrive/akkadian/v2`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb7acb0",
   "metadata": {},
   "source": [
    "## 0. Setup: Kaggle Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1b06e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91631ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle Hub login and data download\n",
    "import kagglehub\n",
    "kagglehub.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cb14c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data from Kaggle\n",
    "kbsooo_akkadian_v2_data_path = kagglehub.dataset_download('kbsooo/akkadian-v2-data')\n",
    "print(f'Data downloaded to: {kbsooo_akkadian_v2_data_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b860f816",
   "metadata": {},
   "source": [
    "## 1. Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e96e52",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from sacrebleu.metrics import BLEU, CHRF\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    set_seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6586a15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Training configuration for Colab GPU.\"\"\"\n",
    "    # Model\n",
    "    model_name: str = \"google/byt5-base\"\n",
    "    \n",
    "    # Paths (Colab + Google Drive)\n",
    "    data_dir: Path = None  # Set after kagglehub download\n",
    "    output_dir: Path = Path(\"/content/drive/MyDrive/akkadian/v2\")\n",
    "    \n",
    "    # Training\n",
    "    seed: int = 42\n",
    "    max_source_length: int = 512\n",
    "    max_target_length: int = 512\n",
    "    batch_size: int = 2\n",
    "    gradient_accumulation_steps: int = 8\n",
    "    epochs: int = 10\n",
    "    learning_rate: float = 3e-4\n",
    "    warmup_ratio: float = 0.05\n",
    "    weight_decay: float = 0.01\n",
    "    \n",
    "    # Hardware\n",
    "    fp16: bool = True\n",
    "    bf16: bool = False\n",
    "    gradient_checkpointing: bool = True\n",
    "    dataloader_num_workers: int = 2\n",
    "\n",
    "\n",
    "CFG = Config()\n",
    "\n",
    "# Set data directory from kagglehub download\n",
    "CFG.data_dir = Path(kbsooo_akkadian_v2_data_path)\n",
    "\n",
    "# Ensure output directory exists\n",
    "CFG.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Data directory: {CFG.data_dir}\")\n",
    "print(f\"üìÅ Output directory: {CFG.output_dir}\")\n",
    "print(f\"üéÆ CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a683299",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b8bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìñ Loading preprocessed data...\")\n",
    "train_df = pd.read_csv(CFG.data_dir / \"v2_train_augmented.csv\")\n",
    "val_df = pd.read_csv(CFG.data_dir / \"v2_val.csv\")\n",
    "\n",
    "print(f\"   Train: {len(train_df)}, Val: {len(val_df)}\")\n",
    "print(f\"\\nüìù Sample:\")\n",
    "print(f\"   src: {train_df.iloc[0]['src'][:80]}...\")\n",
    "print(f\"   tgt: {train_df.iloc[0]['tgt'][:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ea4f1e",
   "metadata": {},
   "source": [
    "## 3. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a4b6c8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(f\"ü§ñ Loading model: {CFG.model_name}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(CFG.model_name)\n",
    "\n",
    "if CFG.gradient_checkpointing:\n",
    "    model.gradient_checkpointing_enable()\n",
    "    print(\"   ‚úÖ Gradient checkpointing enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0c694b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def tokenize_fn(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"src\"],\n",
    "        max_length=CFG.max_source_length,\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "    )\n",
    "    # ByT5: encoder/decoder share same vocab, no as_target_tokenizer() needed\n",
    "    labels = tokenizer(\n",
    "        examples[\"tgt\"],\n",
    "        max_length=CFG.max_target_length,\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "    )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df[[\"src\", \"tgt\"]])\n",
    "val_ds = Dataset.from_pandas(val_df[[\"src\", \"tgt\"]])\n",
    "\n",
    "train_ds = train_ds.map(tokenize_fn, batched=True, remove_columns=[\"src\", \"tgt\"], desc=\"Tokenizing train\")\n",
    "val_ds = val_ds.map(tokenize_fn, batched=True, remove_columns=[\"src\", \"tgt\"], desc=\"Tokenizing val\")\n",
    "\n",
    "print(f\"   Train samples: {len(train_ds)}, Val samples: {len(val_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe689aea",
   "metadata": {},
   "source": [
    "## 4. Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fb3da4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def build_compute_metrics(tokenizer):\n",
    "    bleu = BLEU()\n",
    "    chrf = CHRF(word_order=2)\n",
    "    \n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        if isinstance(predictions, tuple):\n",
    "            predictions = predictions[0]\n",
    "        \n",
    "        predictions = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        \n",
    "        decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "        \n",
    "        decoded_preds = [p.strip() for p in decoded_preds]\n",
    "        decoded_labels = [[l.strip()] for l in decoded_labels]\n",
    "        \n",
    "        bleu_score = bleu.corpus_score(decoded_preds, decoded_labels).score\n",
    "        chrf_score = chrf.corpus_score(decoded_preds, decoded_labels).score\n",
    "        geo_mean = np.sqrt(bleu_score * chrf_score) if bleu_score > 0 and chrf_score > 0 else 0.0\n",
    "        \n",
    "        return {\"bleu\": bleu_score, \"chrf\": chrf_score, \"geo_mean\": geo_mean}\n",
    "    \n",
    "    return compute_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d111a129",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e883e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "\n",
    "class LoggingCallback(TrainerCallback):\n",
    "    \"\"\"Custom callback for cleaner training logs.\"\"\"\n",
    "    \n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        if state.log_history:\n",
    "            last_log = state.log_history[-1]\n",
    "            epoch = last_log.get('epoch', 0)\n",
    "            train_loss = last_log.get('loss', 'N/A')\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"üìä Epoch {int(epoch)} Complete\")\n",
    "            print(f\"   Train Loss: {train_loss:.4f}\" if isinstance(train_loss, float) else f\"   Train Loss: {train_loss}\")\n",
    "    \n",
    "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
    "        if metrics:\n",
    "            print(f\"\\nüìà Validation Results:\")\n",
    "            print(f\"   Loss: {metrics.get('eval_loss', 'N/A'):.4f}\" if metrics.get('eval_loss') else \"   Loss: N/A\")\n",
    "            print(f\"   BLEU: {metrics.get('eval_bleu', 0):.2f}\")\n",
    "            print(f\"   chrF++: {metrics.get('eval_chrf', 0):.2f}\")\n",
    "            print(f\"   Geo Mean: {metrics.get('eval_geo_mean', 0):.2f}\")\n",
    "            print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74efca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, padding=True)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=str(CFG.output_dir / \"checkpoints\"),\n",
    "    num_train_epochs=CFG.epochs,\n",
    "    per_device_train_batch_size=CFG.batch_size,\n",
    "    per_device_eval_batch_size=CFG.batch_size * 2,\n",
    "    gradient_accumulation_steps=CFG.gradient_accumulation_steps,\n",
    "    learning_rate=CFG.learning_rate,\n",
    "    weight_decay=CFG.weight_decay,\n",
    "    warmup_ratio=CFG.warmup_ratio,\n",
    "    fp16=CFG.fp16 and torch.cuda.is_available(),\n",
    "    bf16=CFG.bf16,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_bleu\",\n",
    "    greater_is_better=True,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=CFG.max_target_length,\n",
    "    dataloader_num_workers=CFG.dataloader_num_workers,\n",
    "    logging_steps=100,  # Less frequent logging\n",
    "    logging_first_step=True,\n",
    "    report_to=\"none\",\n",
    "    seed=CFG.seed,\n",
    "    disable_tqdm=False,  # Keep progress bar\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=build_compute_metrics(tokenizer),\n",
    "    callbacks=[LoggingCallback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2955ffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüèãÔ∏è Training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe55df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model to Google Drive\n",
    "final_dir = CFG.output_dir / \"final\"\n",
    "print(f\"\\nüíæ Saving to Google Drive: {final_dir}\")\n",
    "trainer.save_model(str(final_dir))\n",
    "tokenizer.save_pretrained(str(final_dir))\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nüìà Final evaluation:\")\n",
    "results = trainer.evaluate()\n",
    "print(f\"   BLEU: {results.get('eval_bleu', 0):.2f}\")\n",
    "print(f\"   chrF++: {results.get('eval_chrf', 0):.2f}\")\n",
    "print(f\"   Geo Mean: {results.get('eval_geo_mean', 0):.2f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")\n",
    "print(f\"üìÅ Model saved to: {final_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a263f00b",
   "metadata": {},
   "source": [
    "## 6. Create Model Archive (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d49782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "zip_path = CFG.output_dir / \"akkadian_v2_model\"\n",
    "shutil.make_archive(str(zip_path), 'zip', final_dir)\n",
    "print(f\"üì¶ Model archived: {zip_path}.zip\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
