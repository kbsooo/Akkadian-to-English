{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aa1aa3e",
   "metadata": {},
   "source": [
    "# Akkadian V2 Training\n",
    "\n",
    "**Key Changes from V1:**\n",
    "- Unified ASCII normalization (Train/Test style mismatch fixed)\n",
    "- All diacritics converted to ASCII (≈°‚Üís, √†‚Üía, etc.)\n",
    "\n",
    "**Environment**: Kaggle T4 GPU x2\n",
    "\n",
    "**Usage:**\n",
    "```bash\n",
    "uv run jupytext --to notebook src/v2/akka_v2_train.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0425292a",
   "metadata": {},
   "source": [
    "## 1. Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf0ec2b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from sacrebleu.metrics import BLEU, CHRF\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    set_seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebe2226",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Training configuration for Kaggle T4 x2.\"\"\"\n",
    "    # Model\n",
    "    model_name: str = \"google/byt5-base\"\n",
    "    \n",
    "    # Paths\n",
    "    kaggle_input: Path = Path(\"/kaggle/input\")\n",
    "    kaggle_working: Path = Path(\"/kaggle/working\")\n",
    "    \n",
    "    # Training\n",
    "    seed: int = 42\n",
    "    max_source_length: int = 512   # Increased for longer documents\n",
    "    max_target_length: int = 512\n",
    "    batch_size: int = 2            # Per GPU\n",
    "    gradient_accumulation_steps: int = 8\n",
    "    epochs: int = 10               # More epochs\n",
    "    learning_rate: float = 3e-4\n",
    "    warmup_ratio: float = 0.05\n",
    "    weight_decay: float = 0.01\n",
    "    \n",
    "    # Hardware\n",
    "    fp16: bool = True\n",
    "    bf16: bool = False\n",
    "    gradient_checkpointing: bool = True\n",
    "    dataloader_num_workers: int = 2\n",
    "\n",
    "\n",
    "CFG = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c529bbed",
   "metadata": {},
   "source": [
    "## 2. Environment Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaad3e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_kaggle() -> bool:\n",
    "    return Path(\"/kaggle/input\").exists()\n",
    "\n",
    "\n",
    "def find_data_dir() -> Path:\n",
    "    \"\"\"Find V2 preprocessed data.\"\"\"\n",
    "    if is_kaggle():\n",
    "        # On Kaggle: look for v2_train.csv in input datasets\n",
    "        for d in CFG.kaggle_input.iterdir():\n",
    "            if (d / \"v2_train.csv\").exists():\n",
    "                return d\n",
    "        # Fallback: run preprocessing\n",
    "        raise FileNotFoundError(\"V2 data not found. Upload v2_train.csv and v2_val.csv as a dataset.\")\n",
    "    else:\n",
    "        # Local\n",
    "        local = Path(\"data/v2\")\n",
    "        if local.exists():\n",
    "            return local\n",
    "        raise FileNotFoundError(\"Run build_dataset.py first\")\n",
    "\n",
    "\n",
    "def get_output_dir() -> Path:\n",
    "    if is_kaggle():\n",
    "        return CFG.kaggle_working / \"akkadian_v2\"\n",
    "    return Path(\"outputs/akkadian_v2\")\n",
    "\n",
    "\n",
    "DATA_DIR = find_data_dir()\n",
    "OUTPUT_DIR = get_output_dir()\n",
    "\n",
    "print(f\"üìÅ Data directory: {DATA_DIR}\")\n",
    "print(f\"üìÅ Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"üñ•Ô∏è Kaggle: {is_kaggle()}\")\n",
    "print(f\"üéÆ CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPUs: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bd6e8e",
   "metadata": {},
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f0f119",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìñ Loading preprocessed data...\")\n",
    "train_df = pd.read_csv(DATA_DIR / \"v2_train_augmented.csv\")  # Use augmented data\n",
    "val_df = pd.read_csv(DATA_DIR / \"v2_val.csv\")\n",
    "\n",
    "print(f\"   Train: {len(train_df)}, Val: {len(val_df)}\")\n",
    "print(f\"\\nüìù Sample:\")\n",
    "print(f\"   src: {train_df.iloc[0]['src'][:80]}...\")\n",
    "print(f\"   tgt: {train_df.iloc[0]['tgt'][:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bb6829",
   "metadata": {},
   "source": [
    "## 4. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ad85b1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(f\"ü§ñ Loading model: {CFG.model_name}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(CFG.model_name)\n",
    "\n",
    "if CFG.gradient_checkpointing:\n",
    "    model.gradient_checkpointing_enable()\n",
    "    print(\"   ‚úÖ Gradient checkpointing enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd414bbb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def tokenize_fn(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"src\"],\n",
    "        max_length=CFG.max_source_length,\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "    )\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples[\"tgt\"],\n",
    "            max_length=CFG.max_target_length,\n",
    "            truncation=True,\n",
    "            padding=False,\n",
    "        )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df[[\"src\", \"tgt\"]])\n",
    "val_ds = Dataset.from_pandas(val_df[[\"src\", \"tgt\"]])\n",
    "\n",
    "train_ds = train_ds.map(tokenize_fn, batched=True, remove_columns=[\"src\", \"tgt\"], desc=\"Tokenizing train\")\n",
    "val_ds = val_ds.map(tokenize_fn, batched=True, remove_columns=[\"src\", \"tgt\"], desc=\"Tokenizing val\")\n",
    "\n",
    "print(f\"   Train samples: {len(train_ds)}, Val samples: {len(val_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c71b68",
   "metadata": {},
   "source": [
    "## 5. Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00247f71",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def build_compute_metrics(tokenizer):\n",
    "    bleu = BLEU()\n",
    "    chrf = CHRF(word_order=2)\n",
    "    \n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        if isinstance(predictions, tuple):\n",
    "            predictions = predictions[0]\n",
    "        \n",
    "        predictions = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        \n",
    "        decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "        \n",
    "        decoded_preds = [p.strip() for p in decoded_preds]\n",
    "        decoded_labels = [[l.strip()] for l in decoded_labels]\n",
    "        \n",
    "        bleu_score = bleu.corpus_score(decoded_preds, decoded_labels).score\n",
    "        chrf_score = chrf.corpus_score(decoded_preds, decoded_labels).score\n",
    "        geo_mean = np.sqrt(bleu_score * chrf_score) if bleu_score > 0 and chrf_score > 0 else 0.0\n",
    "        \n",
    "        return {\"bleu\": bleu_score, \"chrf\": chrf_score, \"geo_mean\": geo_mean}\n",
    "    \n",
    "    return compute_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be822973",
   "metadata": {},
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f75580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, padding=True)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=str(OUTPUT_DIR),\n",
    "    num_train_epochs=CFG.epochs,\n",
    "    per_device_train_batch_size=CFG.batch_size,\n",
    "    per_device_eval_batch_size=CFG.batch_size * 2,\n",
    "    gradient_accumulation_steps=CFG.gradient_accumulation_steps,\n",
    "    learning_rate=CFG.learning_rate,\n",
    "    weight_decay=CFG.weight_decay,\n",
    "    warmup_ratio=CFG.warmup_ratio,\n",
    "    fp16=CFG.fp16 and torch.cuda.is_available(),\n",
    "    bf16=CFG.bf16,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_bleu\",\n",
    "    greater_is_better=True,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=CFG.max_target_length,\n",
    "    dataloader_num_workers=CFG.dataloader_num_workers,\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    "    seed=CFG.seed,\n",
    "    ddp_find_unused_parameters=False,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=build_compute_metrics(tokenizer),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afb5f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüèãÔ∏è Training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ba1bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "final_dir = OUTPUT_DIR / \"final\"\n",
    "print(f\"\\nüíæ Saving to {final_dir}\")\n",
    "trainer.save_model(str(final_dir))\n",
    "tokenizer.save_pretrained(str(final_dir))\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nüìà Final evaluation:\")\n",
    "results = trainer.evaluate()\n",
    "print(f\"   BLEU: {results.get('eval_bleu', 0):.2f}\")\n",
    "print(f\"   chrF++: {results.get('eval_chrf', 0):.2f}\")\n",
    "print(f\"   Geo Mean: {results.get('eval_geo_mean', 0):.2f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9ae18c",
   "metadata": {},
   "source": [
    "## 7. Create Model Archive\n",
    "\n",
    "For Kaggle Models upload:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c396b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "if is_kaggle():\n",
    "    zip_path = CFG.kaggle_working / \"akkadian_v2_model\"\n",
    "    shutil.make_archive(str(zip_path), 'zip', final_dir)\n",
    "    print(f\"üì¶ Model archived: {zip_path}.zip\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
