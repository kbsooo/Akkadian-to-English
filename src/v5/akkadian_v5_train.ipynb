{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a4ce007",
   "metadata": {},
   "source": [
    "# Akkadian V5 Training (2-stage)\n",
    "\n",
    "Stage A: Publications English doc-level (optional)\n",
    "Stage B: Sentence-level main training\n",
    "\n",
    "Data input: data/v5 or Kaggle input containing v5_* files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4309f70d",
   "metadata": {},
   "source": [
    "## 0. Setup (Colab)\n",
    "\n",
    "Mount Google Drive if running on Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52df9bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive  # type: ignore\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b39fcd",
   "metadata": {},
   "source": [
    "## 1. Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7395b2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from sacrebleu.metrics import BLEU, CHRF\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    TrainerCallback,\n",
    "    set_seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6364bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    model_size: str = \"base\"  # \"base\" or \"large\"\n",
    "    data_dir: Optional[Path] = None\n",
    "    output_dir: Optional[Path] = None\n",
    "\n",
    "    # Stage A (publications)\n",
    "    use_publications_stage: bool = True\n",
    "    stage_a_epochs: int = 2\n",
    "    stage_a_lr: float = 5e-5\n",
    "\n",
    "    # Stage B (sentence-level)\n",
    "    stage_b_epochs: int = 8\n",
    "    stage_b_lr: float = 1e-4\n",
    "\n",
    "    # Sequence lengths\n",
    "    max_source_length: int = 256\n",
    "    max_target_length: int = 256\n",
    "\n",
    "    # Training\n",
    "    seed: int = 42\n",
    "    batch_size: int = 4\n",
    "    gradient_accumulation_steps: int = 4\n",
    "    warmup_ratio: float = 0.1\n",
    "    weight_decay: float = 0.01\n",
    "    max_grad_norm: float = 1.0\n",
    "\n",
    "    # Hardware\n",
    "    fp16: bool = False\n",
    "    bf16: bool = False\n",
    "    gradient_checkpointing: bool = True\n",
    "    dataloader_num_workers: int = 2\n",
    "\n",
    "    # Model-specific\n",
    "    model_name: str = field(init=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.model_size == \"base\":\n",
    "            self.model_name = \"google/byt5-base\"\n",
    "            if self.output_dir is None:\n",
    "                self.output_dir = Path(\"/content/drive/MyDrive/akkadian/v5-base\")\n",
    "        else:\n",
    "            self.model_name = \"google/byt5-large\"\n",
    "            if self.output_dir is None:\n",
    "                self.output_dir = Path(\"/content/drive/MyDrive/akkadian/v5-large\")\n",
    "\n",
    "\n",
    "def resolve_data_dir() -> Path:\n",
    "    env = os.environ.get(\"V5_DATA_DIR\")\n",
    "    if env:\n",
    "        p = Path(env)\n",
    "        if p.exists():\n",
    "            return p\n",
    "\n",
    "    local = Path(\"data/v5\")\n",
    "    if local.exists():\n",
    "        return local\n",
    "\n",
    "    kaggle_input = Path(\"/kaggle/input\")\n",
    "    if kaggle_input.exists():\n",
    "        for d in kaggle_input.iterdir():\n",
    "            if (d / \"v5_sentence_train.csv\").exists():\n",
    "                return d\n",
    "\n",
    "    raise FileNotFoundError(\"V5 data directory not found. Set V5_DATA_DIR or place data/v5.\")\n",
    "\n",
    "\n",
    "CFG = Config(model_size=\"base\")\n",
    "CFG.data_dir = resolve_data_dir()\n",
    "CFG.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"üöÄ Akkadian V5 Training: {CFG.model_size.upper()}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üìÅ Data: {CFG.data_dir}\")\n",
    "print(f\"üìÅ Output: {CFG.output_dir}\")\n",
    "print(f\"ü§ñ Model: {CFG.model_name}\")\n",
    "print(f\"üéÆ CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "set_seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9b3bc4",
   "metadata": {},
   "source": [
    "## 2. Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc54b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pairs(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    if not {\"src\", \"tgt\"}.issubset(df.columns):\n",
    "        raise ValueError(f\"Missing src/tgt columns: {path}\")\n",
    "    df = df.dropna(subset=[\"src\", \"tgt\"]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_compute_metrics(tokenizer):\n",
    "    bleu = BLEU()\n",
    "    chrf = CHRF(word_order=2)\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        if isinstance(predictions, tuple):\n",
    "            predictions = predictions[0]\n",
    "\n",
    "        predictions = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "\n",
    "        decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "        decoded_preds = [p.strip() for p in decoded_preds]\n",
    "        decoded_labels = [[l.strip()] for l in decoded_labels]\n",
    "\n",
    "        bleu_score = bleu.corpus_score(decoded_preds, decoded_labels).score\n",
    "        chrf_score = chrf.corpus_score(decoded_preds, decoded_labels).score\n",
    "        geo_mean = np.sqrt(bleu_score * chrf_score) if bleu_score > 0 and chrf_score > 0 else 0.0\n",
    "\n",
    "        return {\"bleu\": bleu_score, \"chrf\": chrf_score, \"geo_mean\": geo_mean}\n",
    "\n",
    "    return compute_metrics\n",
    "\n",
    "\n",
    "class LogCallback(TrainerCallback):\n",
    "    def __init__(self, label: str):\n",
    "        self.label = label\n",
    "        self.epoch = 0\n",
    "        self.losses = []\n",
    "\n",
    "    def on_epoch_begin(self, args, state, control, **kwargs):\n",
    "        self.epoch = int(state.epoch) if state.epoch else 0\n",
    "        self.losses = []\n",
    "        print(f\"\\n{'='*60}\\nüìä {self.label} Epoch {self.epoch + 1}/{args.num_train_epochs}\\n{'='*60}\")\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs and \"loss\" in logs:\n",
    "            self.losses.append(logs[\"loss\"])\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        if self.losses:\n",
    "            print(f\"\\nüìâ {self.label} Train Loss: {sum(self.losses)/len(self.losses):.4f}\")\n",
    "\n",
    "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
    "        if metrics:\n",
    "            print(f\"\\n{'‚îÄ'*40}\\nüìà Validation ({self.label})\\n{'‚îÄ'*40}\")\n",
    "            print(f\"   BLEU: {metrics.get('eval_bleu', 0):.2f}\")\n",
    "            print(f\"   chrF: {metrics.get('eval_chrf', 0):.2f}\")\n",
    "            print(f\"   Geo:  {metrics.get('eval_geo_mean', 0):.2f}\\n{'‚îÄ'*40}\")\n",
    "\n",
    "\n",
    "class HistoryCallback(TrainerCallback):\n",
    "    \"\"\"Collect training/eval metrics for plotting.\"\"\"\n",
    "\n",
    "    def __init__(self, label: str):\n",
    "        self.label = label\n",
    "        self.train_steps: list[int] = []\n",
    "        self.train_losses: list[float] = []\n",
    "        self.eval_epochs: list[float] = []\n",
    "        self.eval_bleu: list[float] = []\n",
    "        self.eval_chrf: list[float] = []\n",
    "        self.eval_geo: list[float] = []\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs and \"loss\" in logs:\n",
    "            self.train_steps.append(int(state.global_step))\n",
    "            self.train_losses.append(float(logs[\"loss\"]))\n",
    "\n",
    "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
    "        if not metrics:\n",
    "            return\n",
    "        epoch = float(state.epoch) if state.epoch is not None else 0.0\n",
    "        self.eval_epochs.append(epoch)\n",
    "        self.eval_bleu.append(float(metrics.get(\"eval_bleu\", 0.0)))\n",
    "        self.eval_chrf.append(float(metrics.get(\"eval_chrf\", 0.0)))\n",
    "        self.eval_geo.append(float(metrics.get(\"eval_geo_mean\", 0.0)))\n",
    "\n",
    "    def plot(self):\n",
    "        if not self.train_steps and not self.eval_epochs:\n",
    "            return\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        if self.train_steps:\n",
    "            axes[0].plot(self.train_steps, self.train_losses, label=\"train_loss\")\n",
    "            axes[0].set_title(f\"{self.label} Train Loss\")\n",
    "            axes[0].set_xlabel(\"step\")\n",
    "            axes[0].set_ylabel(\"loss\")\n",
    "            axes[0].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[0].set_visible(False)\n",
    "\n",
    "        if self.eval_epochs:\n",
    "            axes[1].plot(self.eval_epochs, self.eval_bleu, label=\"BLEU\")\n",
    "            axes[1].plot(self.eval_epochs, self.eval_chrf, label=\"chrF\")\n",
    "            axes[1].plot(self.eval_epochs, self.eval_geo, label=\"GeoMean\")\n",
    "            axes[1].set_title(f\"{self.label} Eval Metrics\")\n",
    "            axes[1].set_xlabel(\"epoch\")\n",
    "            axes[1].set_ylabel(\"score\")\n",
    "            axes[1].legend()\n",
    "            axes[1].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[1].set_visible(False)\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453a3bf2",
   "metadata": {},
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6793fb36",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"üìñ Loading V5 datasets...\")\n",
    "\n",
    "sentence_train_path = CFG.data_dir / \"v5_sentence_train.csv\"\n",
    "sentence_val_path = CFG.data_dir / \"v5_sentence_val.csv\"\n",
    "\n",
    "if not sentence_train_path.exists() or not sentence_val_path.exists():\n",
    "    raise FileNotFoundError(\"v5_sentence_train/val.csv not found in data dir\")\n",
    "\n",
    "sent_train_df = load_pairs(sentence_train_path)\n",
    "sent_val_df = load_pairs(sentence_val_path)\n",
    "\n",
    "pub_pairs_path = CFG.data_dir / \"v5_publications_doc_pairs.csv\"\n",
    "pub_df = load_pairs(pub_pairs_path) if pub_pairs_path.exists() else None\n",
    "\n",
    "print(f\"   Sentence train: {len(sent_train_df):,}\")\n",
    "print(f\"   Sentence val: {len(sent_val_df):,}\")\n",
    "if pub_df is not None:\n",
    "    print(f\"   Publications doc pairs: {len(pub_df):,}\")\n",
    "else:\n",
    "    print(\"   Publications doc pairs: not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8670432",
   "metadata": {},
   "source": [
    "## 4. Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6de8e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nü§ñ Loading model: {CFG.model_name}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(CFG.model_name)\n",
    "\n",
    "print(f\"   Tokenizer: {len(tokenizer)}, Model vocab: {model.config.vocab_size}\")\n",
    "print(f\"   Params: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "if CFG.gradient_checkpointing:\n",
    "    model.gradient_checkpointing_enable()\n",
    "    print(\"   ‚úÖ Gradient checkpointing enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883ba30e",
   "metadata": {},
   "source": [
    "## 5. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a98511",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenize_fn(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"src\"],\n",
    "        max_length=CFG.max_source_length,\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        examples[\"tgt\"],\n",
    "        max_length=CFG.max_target_length,\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "    )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "def to_dataset(df: pd.DataFrame) -> Dataset:\n",
    "    ds = Dataset.from_pandas(df[[\"src\", \"tgt\"]])\n",
    "    return ds.map(tokenize_fn, batched=True, remove_columns=[\"src\", \"tgt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a89363",
   "metadata": {},
   "source": [
    "## 6. Stage A: Publications Doc-Level (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cfb67a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if CFG.use_publications_stage and pub_df is not None and len(pub_df) > 0:\n",
    "    print(\"\\nüèÅ Stage A: Publications doc-level\")\n",
    "    pub_train_ds = to_dataset(pub_df)\n",
    "\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, padding=True)\n",
    "    history_a = HistoryCallback(\"Stage A\")\n",
    "\n",
    "    stage_a_args = dict(\n",
    "        output_dir=str(CFG.output_dir / \"stage_a_checkpoints\"),\n",
    "        num_train_epochs=CFG.stage_a_epochs,\n",
    "        per_device_train_batch_size=CFG.batch_size,\n",
    "        gradient_accumulation_steps=CFG.gradient_accumulation_steps,\n",
    "        learning_rate=CFG.stage_a_lr,\n",
    "        weight_decay=CFG.weight_decay,\n",
    "        warmup_ratio=CFG.warmup_ratio,\n",
    "        max_grad_norm=CFG.max_grad_norm,\n",
    "        fp16=CFG.fp16,\n",
    "        bf16=CFG.bf16,\n",
    "        evaluation_strategy=\"no\",\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=1,\n",
    "        predict_with_generate=False,\n",
    "        dataloader_num_workers=CFG.dataloader_num_workers,\n",
    "        logging_steps=50,\n",
    "        report_to=\"none\",\n",
    "        seed=CFG.seed,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        training_args = Seq2SeqTrainingArguments(**stage_a_args)\n",
    "    except TypeError:\n",
    "        stage_a_args[\"eval_strategy\"] = stage_a_args.pop(\"evaluation_strategy\")\n",
    "        training_args = Seq2SeqTrainingArguments(**stage_a_args)\n",
    "\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=pub_train_ds,\n",
    "        processing_class=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        callbacks=[LogCallback(\"Stage A\"), history_a],\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    history_a.plot()\n",
    "else:\n",
    "    print(\"\\n‚è≠Ô∏è  Stage A skipped (no publications data or disabled)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e0d305",
   "metadata": {},
   "source": [
    "## 7. Stage B: Sentence-Level Main Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50092cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüèÅ Stage B: Sentence-level training\")\n",
    "\n",
    "sent_train_ds = to_dataset(sent_train_df)\n",
    "sent_val_ds = to_dataset(sent_val_df)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, padding=True)\n",
    "\n",
    "stage_b_args = dict(\n",
    "    output_dir=str(CFG.output_dir / \"stage_b_checkpoints\"),\n",
    "    num_train_epochs=CFG.stage_b_epochs,\n",
    "    per_device_train_batch_size=CFG.batch_size,\n",
    "    per_device_eval_batch_size=CFG.batch_size * 2,\n",
    "    gradient_accumulation_steps=CFG.gradient_accumulation_steps,\n",
    "    learning_rate=CFG.stage_b_lr,\n",
    "    weight_decay=CFG.weight_decay,\n",
    "    warmup_ratio=CFG.warmup_ratio,\n",
    "    max_grad_norm=CFG.max_grad_norm,\n",
    "    fp16=CFG.fp16,\n",
    "    bf16=CFG.bf16,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_geo_mean\",\n",
    "    greater_is_better=True,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=CFG.max_target_length,\n",
    "    dataloader_num_workers=CFG.dataloader_num_workers,\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    "    seed=CFG.seed,\n",
    ")\n",
    "\n",
    "try:\n",
    "    training_args = Seq2SeqTrainingArguments(**stage_b_args)\n",
    "except TypeError:\n",
    "    stage_b_args[\"eval_strategy\"] = stage_b_args.pop(\"evaluation_strategy\")\n",
    "    training_args = Seq2SeqTrainingArguments(**stage_b_args)\n",
    "\n",
    "history_b = HistoryCallback(\"Stage B\")\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=sent_train_ds,\n",
    "    eval_dataset=sent_val_ds,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=build_compute_metrics(tokenizer),\n",
    "    callbacks=[LogCallback(\"Stage B\"), history_b],\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "history_b.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a8beea",
   "metadata": {},
   "source": [
    "## 8. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb9a2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = CFG.output_dir / \"model\"\n",
    "trainer.save_model(str(model_dir))\n",
    "tokenizer.save_pretrained(str(model_dir))\n",
    "print(f\"\\nüíæ Saved: {model_dir}\")\n",
    "\n",
    "results = trainer.evaluate()\n",
    "print(f\"\\nüìà Final: BLEU={results.get('eval_bleu',0):.2f}, chrF={results.get('eval_chrf',0):.2f}, Geo={results.get('eval_geo_mean',0):.2f}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\\n‚úÖ V5 Training Complete!\\n{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
