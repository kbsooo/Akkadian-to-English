{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5233bf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"akkadian_v5b_train.ipynb\n",
    "\n",
    "Automatically generated by Colab.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/13Tup1kPmEkrrMMI7DXSzZ0w361ZP_3Cm\n",
    "\n",
    "# Akkadian V5b Training (Glossary-Prompt)\n",
    "\n",
    "Stage A: Publications English doc-level (optional)\n",
    "Stage B: Sentence-level main training with glossary prompts\n",
    "\n",
    "## 0. Setup (Colab)\n",
    "\n",
    "Mount Google Drive if running on Colab.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fdbb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive  # type: ignore\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43406690",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## 1. Imports & Configuration\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594c30b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99357e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f09fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e4daf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from sacrebleu.metrics import BLEU, CHRF\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    ByT5Tokenizer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    TrainerCallback,\n",
    "    set_seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15292b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_SPLIT_RE = re.compile(r\"[\\s\\-]+\")\n",
    "TGT_TOKEN_RE = re.compile(r\"[A-Za-z][A-Za-z'\\-]*|\\d+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dda9055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_src(text: str) -> list[str]:\n",
    "    if not text:\n",
    "        return []\n",
    "    return [t for t in SRC_SPLIT_RE.split(str(text)) if t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4265635a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def tokenize_tgt(text: str) -> list[str]:\n",
    "    if not text:\n",
    "        return []\n",
    "    return TGT_TOKEN_RE.findall(str(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c388d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    model_size: str = \"small\"  # \"base\" or \"large\" or small\n",
    "    data_dir: Optional[Path] = None\n",
    "    output_dir: Optional[Path] = None\n",
    "\n",
    "    # Stage A (publications)\n",
    "    use_publications_stage: bool = True\n",
    "    stage_a_epochs: int = 2\n",
    "    stage_a_lr: float = 5e-5\n",
    "\n",
    "    # Stage B (sentence-level)\n",
    "    stage_b_epochs: int = 8\n",
    "    stage_b_lr: float = 1e-4\n",
    "\n",
    "    # Sequence lengths\n",
    "    max_source_length: int = 256\n",
    "    max_target_length: int = 256\n",
    "\n",
    "    # Training\n",
    "    seed: int = 42\n",
    "    # A100 40GB: push larger per-device batch and use modest accumulation\n",
    "    batch_size: int = 16\n",
    "    gradient_accumulation_steps: int = 2\n",
    "    warmup_ratio: float = 0.1\n",
    "    weight_decay: float = 0.01\n",
    "    max_grad_norm: float = 1.0\n",
    "\n",
    "    # Hardware\n",
    "    fp16: bool = False\n",
    "    bf16: bool = True\n",
    "    gradient_checkpointing: bool = False\n",
    "    dataloader_num_workers: int = 4\n",
    "\n",
    "    # Glossary prompt\n",
    "    use_glossary_prompt: bool = True\n",
    "    glossary_path: Optional[Path] = None\n",
    "    glossary_max_items: int = 8\n",
    "    glossary_drop_prob_train: float = 0.5\n",
    "    glossary_drop_prob_eval: float = 0.0\n",
    "\n",
    "    # Glossary build params (if file missing)\n",
    "    glossary_min_src_count: int = 5\n",
    "    glossary_min_pair_count: int = 2\n",
    "    glossary_min_score: float = 0.15\n",
    "    glossary_max_targets: int = 2\n",
    "    glossary_min_src_len: int = 2\n",
    "    glossary_min_tgt_len: int = 2\n",
    "\n",
    "    # Model-specific\n",
    "    model_name: str = field(init=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.model_size == \"small\":\n",
    "            self.model_name = \"google/byt5-small\"\n",
    "            if self.output_dir is None:\n",
    "                self.output_dir = Path(\"/content/drive/MyDrive/akkadian/v5b-small\")\n",
    "        elif self.model_size == \"base\":\n",
    "            self.model_name = \"google/byt5-base\"\n",
    "            if self.output_dir is None:\n",
    "                self.output_dir = Path(\"/content/drive/MyDrive/akkadian/v5b-base\")\n",
    "        else:\n",
    "            self.model_name = \"google/byt5-large\"\n",
    "            if self.output_dir is None:\n",
    "                self.output_dir = Path(\"/content/drive/MyDrive/akkadian/v5b-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cc3f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_data_dir() -> Path:\n",
    "    env = os.environ.get(\"V5B_DATA_DIR\")\n",
    "    if env:\n",
    "        p = Path(env)\n",
    "        if p.exists():\n",
    "            return p\n",
    "\n",
    "    # Colab common locations (Google Drive)\n",
    "    colab_candidates = [\n",
    "        Path(\"/content/drive/MyDrive/akkadian/data/v5b\"),\n",
    "        Path(\"/content/drive/MyDrive/akkadian/v5b\"),\n",
    "        Path(\"/content/drive/MyDrive/data/v5b\"),\n",
    "        Path(\"/content/drive/MyDrive/v5b\"),\n",
    "    ]\n",
    "    for p in colab_candidates:\n",
    "        if (p / \"v5_sentence_train.csv\").exists():\n",
    "            return p\n",
    "\n",
    "    local = Path(\"data/v5b\")\n",
    "    if local.exists():\n",
    "        return local\n",
    "\n",
    "    fallback = Path(\"data/v5\")\n",
    "    if fallback.exists():\n",
    "        return fallback\n",
    "\n",
    "    kaggle_input = Path(\"/kaggle/input\")\n",
    "    if kaggle_input.exists():\n",
    "        for d in kaggle_input.iterdir():\n",
    "            if (d / \"v5_sentence_train.csv\").exists():\n",
    "                return d\n",
    "\n",
    "    raise FileNotFoundError(\n",
    "        \"V5b data directory not found. Set V5B_DATA_DIR or place data/v5b. \"\n",
    "        \"For Colab, put data in /content/drive/MyDrive/akkadian/data/v5b (or similar).\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa18046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_glossary_path(data_dir: Path) -> Optional[Path]:\n",
    "    candidates = [\n",
    "        data_dir / \"v5b_glossary.json\",\n",
    "        Path(\"data/v5b/v5b_glossary.json\"),\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da475bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = Config(model_size=\"small\")\n",
    "CFG.data_dir = resolve_data_dir()\n",
    "CFG.glossary_path = resolve_glossary_path(CFG.data_dir)\n",
    "CFG.output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901aa2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef8904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(f\"üöÄ Akkadian V5b Training: {CFG.model_size.upper()}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üìÅ Data: {CFG.data_dir}\")\n",
    "print(f\"üìÅ Output: {CFG.output_dir}\")\n",
    "print(f\"ü§ñ Model: {CFG.model_name}\")\n",
    "print(f\"üéÆ CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56c7974",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6496f879",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\"\"\"## 2. Helpers\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0dcfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pairs(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    if not {\"src\", \"tgt\"}.issubset(df.columns):\n",
    "        raise ValueError(f\"Missing src/tgt columns: {path}\")\n",
    "    df = df.dropna(subset=[\"src\", \"tgt\"]).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7945b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_glossary_from_df(df: pd.DataFrame) -> dict[str, list[str]]:\n",
    "    src_count: Counter[str] = Counter()\n",
    "    cooc: dict[str, Counter[str]] = defaultdict(Counter)\n",
    "\n",
    "    for src, tgt in zip(df[\"src\"], df[\"tgt\"]):\n",
    "        src_tokens = set(t for t in tokenize_src(src) if len(t) >= CFG.glossary_min_src_len)\n",
    "        tgt_tokens = set(t for t in tokenize_tgt(tgt) if len(t) >= CFG.glossary_min_tgt_len)\n",
    "        if not src_tokens or not tgt_tokens:\n",
    "            continue\n",
    "        for s in src_tokens:\n",
    "            src_count[s] += 1\n",
    "        for s in src_tokens:\n",
    "            for t in tgt_tokens:\n",
    "                cooc[s][t] += 1\n",
    "\n",
    "    glossary: dict[str, list[str]] = {}\n",
    "    for s, total in src_count.items():\n",
    "        if total < CFG.glossary_min_src_count:\n",
    "            continue\n",
    "        candidates = []\n",
    "        for t, c in cooc[s].items():\n",
    "            if c < CFG.glossary_min_pair_count:\n",
    "                continue\n",
    "            score = c / total\n",
    "            if score < CFG.glossary_min_score:\n",
    "                continue\n",
    "            candidates.append((score, c, t))\n",
    "        candidates.sort(key=lambda x: (-x[0], -x[1], x[2]))\n",
    "        if candidates:\n",
    "            glossary[s] = [t for _, _, t in candidates[: CFG.glossary_max_targets]]\n",
    "\n",
    "    return glossary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839b7428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glossary(path: Path) -> dict[str, list[str]]:\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return {k: list(v) for k, v in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ce7408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_glossary_prompt(\n",
    "    src: str,\n",
    "    glossary: dict[str, list[str]] | None,\n",
    "    max_items: int,\n",
    "    drop_prob: float,\n",
    "    rng: random.Random,\n",
    ") -> str:\n",
    "    if not glossary:\n",
    "        return src\n",
    "    if drop_prob > 0 and rng.random() < drop_prob:\n",
    "        return src\n",
    "\n",
    "    items: list[str] = []\n",
    "    used = set()\n",
    "    for tok in tokenize_src(src):\n",
    "        if tok in used:\n",
    "            continue\n",
    "        tgts = glossary.get(tok)\n",
    "        if not tgts:\n",
    "            continue\n",
    "        tgt = tgts[0]\n",
    "        items.append(f\"{tok}={tgt}\")\n",
    "        used.add(tok)\n",
    "        if len(items) >= max_items:\n",
    "            break\n",
    "\n",
    "    if not items:\n",
    "        return src\n",
    "\n",
    "    return \"GLOSSARY: \" + \"; \".join(items) + \" ||| \" + src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb330dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_glossary(df: pd.DataFrame, glossary: dict[str, list[str]], drop_prob: float, seed: int) -> pd.DataFrame:\n",
    "    rng = random.Random(seed)\n",
    "    df = df.copy()\n",
    "    df[\"src_aug\"] = [\n",
    "        build_glossary_prompt(src, glossary, CFG.glossary_max_items, drop_prob, rng)\n",
    "        for src in df[\"src\"].tolist()\n",
    "    ]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68439f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_compute_metrics(tokenizer):\n",
    "    bleu = BLEU()\n",
    "    chrf = CHRF(word_order=2)\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        if isinstance(predictions, tuple):\n",
    "            predictions = predictions[0]\n",
    "\n",
    "        predictions = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "\n",
    "        decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "        decoded_preds = [p.strip() for p in decoded_preds]\n",
    "        decoded_labels = [[l.strip()] for l in decoded_labels]\n",
    "\n",
    "        bleu_score = bleu.corpus_score(decoded_preds, decoded_labels).score\n",
    "        chrf_score = chrf.corpus_score(decoded_preds, decoded_labels).score\n",
    "        geo_mean = np.sqrt(bleu_score * chrf_score) if bleu_score > 0 and chrf_score > 0 else 0.0\n",
    "\n",
    "        return {\"bleu\": bleu_score, \"chrf\": chrf_score, \"geo_mean\": geo_mean}\n",
    "\n",
    "    return compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244ba129",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogCallback(TrainerCallback):\n",
    "    def __init__(self, label: str):\n",
    "        self.label = label\n",
    "        self.epoch = 0\n",
    "        self.losses = []\n",
    "\n",
    "    def on_epoch_begin(self, args, state, control, **kwargs):\n",
    "        self.epoch = int(state.epoch) if state.epoch else 0\n",
    "        self.losses = []\n",
    "        print(f\"\\n{'='*60}\\nüìä {self.label} Epoch {self.epoch + 1}/{args.num_train_epochs}\\n{'='*60}\")\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs and \"loss\" in logs:\n",
    "            self.losses.append(logs[\"loss\"])\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        if self.losses:\n",
    "            print(f\"\\nüìâ {self.label} Train Loss: {sum(self.losses)/len(self.losses):.4f}\")\n",
    "\n",
    "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
    "        if metrics:\n",
    "            print(f\"\\n{'‚îÄ'*40}\\nüìà Validation ({self.label})\\n{'‚îÄ'*40}\")\n",
    "            print(f\"   BLEU: {metrics.get('eval_bleu', 0):.2f}\")\n",
    "            print(f\"   chrF: {metrics.get('eval_chrf', 0):.2f}\")\n",
    "            print(f\"   Geo:  {metrics.get('eval_geo_mean', 0):.2f}\\n{'‚îÄ'*40}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6cb8b8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class HistoryCallback(TrainerCallback):\n",
    "    \"\"\"Collect training/eval metrics for plotting.\"\"\"\n",
    "\n",
    "    def __init__(self, label: str):\n",
    "        self.label = label\n",
    "        self.train_steps: list[int] = []\n",
    "        self.train_losses: list[float] = []\n",
    "        self.eval_epochs: list[float] = []\n",
    "        self.eval_bleu: list[float] = []\n",
    "        self.eval_chrf: list[float] = []\n",
    "        self.eval_geo: list[float] = []\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs and \"loss\" in logs:\n",
    "            self.train_steps.append(int(state.global_step))\n",
    "            self.train_losses.append(float(logs[\"loss\"]))\n",
    "\n",
    "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
    "        if not metrics:\n",
    "            return\n",
    "        epoch = float(state.epoch) if state.epoch is not None else 0.0\n",
    "        self.eval_epochs.append(epoch)\n",
    "        self.eval_bleu.append(float(metrics.get(\"eval_bleu\", 0.0)))\n",
    "        self.eval_chrf.append(float(metrics.get(\"eval_chrf\", 0.0)))\n",
    "        self.eval_geo.append(float(metrics.get(\"eval_geo_mean\", 0.0)))\n",
    "\n",
    "    def plot(self):\n",
    "        if not self.train_steps and not self.eval_epochs:\n",
    "            return\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        if self.train_steps:\n",
    "            axes[0].plot(self.train_steps, self.train_losses, label=\"train_loss\")\n",
    "            axes[0].set_title(f\"{self.label} Train Loss\")\n",
    "            axes[0].set_xlabel(\"step\")\n",
    "            axes[0].set_ylabel(\"loss\")\n",
    "            axes[0].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[0].set_visible(False)\n",
    "\n",
    "        if self.eval_epochs:\n",
    "            axes[1].plot(self.eval_epochs, self.eval_bleu, label=\"BLEU\")\n",
    "            axes[1].plot(self.eval_epochs, self.eval_chrf, label=\"chrF\")\n",
    "            axes[1].plot(self.eval_epochs, self.eval_geo, label=\"GeoMean\")\n",
    "            axes[1].set_title(f\"{self.label} Eval Metrics\")\n",
    "            axes[1].set_xlabel(\"epoch\")\n",
    "            axes[1].set_ylabel(\"score\")\n",
    "            axes[1].legend()\n",
    "            axes[1].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[1].set_visible(False)\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22ae881",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## 3. Load Data\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c500da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìñ Loading V5b datasets...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e337f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_train_path = CFG.data_dir / \"v5_sentence_train.csv\"\n",
    "sentence_val_path = CFG.data_dir / \"v5_sentence_val.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16abc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not sentence_train_path.exists() or not sentence_val_path.exists():\n",
    "    raise FileNotFoundError(\"v5_sentence_train/val.csv not found in data dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c116fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_train_df = load_pairs(sentence_train_path)\n",
    "sent_val_df = load_pairs(sentence_val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d3d02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_pairs_path = CFG.data_dir / \"v5_publications_doc_pairs.csv\"\n",
    "pub_df = load_pairs(pub_pairs_path) if pub_pairs_path.exists() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9617a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"   Sentence train: {len(sent_train_df):,}\")\n",
    "print(f\"   Sentence val: {len(sent_val_df):,}\")\n",
    "if pub_df is not None:\n",
    "    print(f\"   Publications doc pairs: {len(pub_df):,}\")\n",
    "else:\n",
    "    print(\"   Publications doc pairs: not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560446e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## 4. Glossary Prompt (Stage B)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dd47a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.use_glossary_prompt:\n",
    "    glossary = None\n",
    "    if CFG.glossary_path and CFG.glossary_path.exists():\n",
    "        print(f\"üß† Loading glossary: {CFG.glossary_path}\")\n",
    "        glossary = load_glossary(CFG.glossary_path)\n",
    "    else:\n",
    "        print(\"üß† Building glossary from train set (file not found)\")\n",
    "        glossary = build_glossary_from_df(sent_train_df)\n",
    "\n",
    "    print(f\"   Glossary size: {len(glossary):,}\")\n",
    "\n",
    "    sent_train_df = apply_glossary(\n",
    "        sent_train_df,\n",
    "        glossary,\n",
    "        drop_prob=CFG.glossary_drop_prob_train,\n",
    "        seed=CFG.seed,\n",
    "    )\n",
    "    sent_val_df = apply_glossary(\n",
    "        sent_val_df,\n",
    "        glossary,\n",
    "        drop_prob=CFG.glossary_drop_prob_eval,\n",
    "        seed=CFG.seed,\n",
    "    )\n",
    "else:\n",
    "    print(\"üß† Glossary prompt disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8647e8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## 5. Model Setup\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f24586",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nü§ñ Loading model: {CFG.model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb2acb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ByT5Tokenizer.from_pretrained(CFG.model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(CFG.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b607b344",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"   Tokenizer: {len(tokenizer)}, Model vocab: {model.config.vocab_size}\")\n",
    "print(f\"   Params: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc63dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.gradient_checkpointing:\n",
    "    model.gradient_checkpointing_enable()\n",
    "    print(\"   ‚úÖ Gradient checkpointing enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcadd6c1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\"\"\"## 6. Tokenization\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10f72ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(examples):\n",
    "    src_key = \"src_aug\" if \"src_aug\" in examples else \"src\"\n",
    "    model_inputs = tokenizer(\n",
    "        examples[src_key],\n",
    "        max_length=CFG.max_source_length,\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        examples[\"tgt\"],\n",
    "        max_length=CFG.max_target_length,\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "    )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611ec7fb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def to_dataset(df: pd.DataFrame) -> Dataset:\n",
    "    cols = [\"src\", \"tgt\"]\n",
    "    if \"src_aug\" in df.columns:\n",
    "        cols.append(\"src_aug\")\n",
    "    ds = Dataset.from_pandas(df[cols])\n",
    "    return ds.map(tokenize_fn, batched=True, remove_columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce29a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## 7. Stage A: Publications Doc-Level (optional)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912805b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.use_publications_stage and pub_df is not None and len(pub_df) > 0:\n",
    "    print(\"\\nüèÅ Stage A: Publications doc-level\")\n",
    "    pub_train_ds = to_dataset(pub_df)\n",
    "\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, padding=True)\n",
    "    history_a = HistoryCallback(\"Stage A\")\n",
    "\n",
    "    stage_a_args = dict(\n",
    "        output_dir=str(CFG.output_dir / \"stage_a_checkpoints\"),\n",
    "        num_train_epochs=CFG.stage_a_epochs,\n",
    "        per_device_train_batch_size=CFG.batch_size,\n",
    "        gradient_accumulation_steps=CFG.gradient_accumulation_steps,\n",
    "        learning_rate=CFG.stage_a_lr,\n",
    "        weight_decay=CFG.weight_decay,\n",
    "        warmup_ratio=CFG.warmup_ratio,\n",
    "        max_grad_norm=CFG.max_grad_norm,\n",
    "        fp16=CFG.fp16,\n",
    "        bf16=CFG.bf16,\n",
    "        evaluation_strategy=\"no\",\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=1,\n",
    "        predict_with_generate=False,\n",
    "        dataloader_num_workers=CFG.dataloader_num_workers,\n",
    "        logging_steps=50,\n",
    "        report_to=\"none\",\n",
    "        seed=CFG.seed,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        training_args = Seq2SeqTrainingArguments(**stage_a_args)\n",
    "    except TypeError:\n",
    "        stage_a_args[\"eval_strategy\"] = stage_a_args.pop(\"evaluation_strategy\")\n",
    "        training_args = Seq2SeqTrainingArguments(**stage_a_args)\n",
    "\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=pub_train_ds,\n",
    "        processing_class=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        callbacks=[LogCallback(\"Stage A\"), history_a],\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    history_a.plot()\n",
    "else:\n",
    "    print(\"\\n‚è≠Ô∏è  Stage A skipped (no publications data or disabled)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb62581",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## 8. Stage B: Sentence-Level Main Training\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9bd5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüèÅ Stage B: Sentence-level training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40515f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_train_ds = to_dataset(sent_train_df)\n",
    "sent_val_ds = to_dataset(sent_val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc47f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbe0cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_b_args = dict(\n",
    "    output_dir=str(CFG.output_dir / \"stage_b_checkpoints\"),\n",
    "    num_train_epochs=CFG.stage_b_epochs,\n",
    "    per_device_train_batch_size=CFG.batch_size,\n",
    "    per_device_eval_batch_size=CFG.batch_size * 2,\n",
    "    gradient_accumulation_steps=CFG.gradient_accumulation_steps,\n",
    "    learning_rate=CFG.stage_b_lr,\n",
    "    weight_decay=CFG.weight_decay,\n",
    "    warmup_ratio=CFG.warmup_ratio,\n",
    "    max_grad_norm=CFG.max_grad_norm,\n",
    "    fp16=CFG.fp16,\n",
    "    bf16=CFG.bf16,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_geo_mean\",\n",
    "    greater_is_better=True,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=CFG.max_target_length,\n",
    "    dataloader_num_workers=CFG.dataloader_num_workers,\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    "    seed=CFG.seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429ceded",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    training_args = Seq2SeqTrainingArguments(**stage_b_args)\n",
    "except TypeError:\n",
    "    stage_b_args[\"eval_strategy\"] = stage_b_args.pop(\"evaluation_strategy\")\n",
    "    training_args = Seq2SeqTrainingArguments(**stage_b_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24fef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_b = HistoryCallback(\"Stage B\")\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=sent_train_ds,\n",
    "    eval_dataset=sent_val_ds,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=build_compute_metrics(tokenizer),\n",
    "    callbacks=[LogCallback(\"Stage B\"), history_b],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07885a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "history_b.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a806552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## 9. Save Model\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc28c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = CFG.output_dir / \"model\"\n",
    "trainer.save_model(str(model_dir))\n",
    "tokenizer.save_pretrained(str(model_dir))\n",
    "print(f\"\\nüíæ Saved: {model_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745714c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate()\n",
    "print(f\"\\nüìà Final: BLEU={results.get('eval_bleu',0):.2f}, chrF={results.get('eval_chrf',0):.2f}, Geo={results.get('eval_geo_mean',0):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e48e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*60}\\n‚úÖ V5b Training Complete!\\n{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
