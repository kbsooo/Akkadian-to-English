# 버전 흐름 기록 (V1 → V2)

이 문서는 계획이 아니라 **실제로 시도한 것과 결과**를 정리한 기록이다.

---

## V1

### 목표
- 기본 베이스라인을 빠르게 만들고 성능 확인
- 전처리 파이프라인 구축 후 sentence‑level 데이터 생성

### 주요 시도
- **전처리 파이프라인**
  - 규칙 기반 + 어노테이션 기반 병합
  - 품질 점수/패턴 필터 도입
  - Tier 구성:
    - Tier1: valid 전체
    - Tier2: min_quality ≥ 0.7
    - Tier3: min_quality ≥ 0.7 + 패턴 필터
  - 결과: **Tier3 약 2,350쌍** 생성

- **학습**
  - 로컬(MPS) 베이스라인 시도
  - Kaggle용 학습 템플릿 구성

- **추론**
  - Kaggle inference notebook 구성
  - 모델 로딩/토크나이저 불일치 의심

### 결과
- **Public score: 0.0**
- 제출 파일에 `!!!!` 반복 출력 발생

### 실패 원인(사후 분석)
1) **모델/체크포인트 불일치 가능성**
   - 학습 시 사용 모델과 업로드 모델 구조가 다름
2) **Train/Test 전처리 불일치**
   - 문서 레벨 학습 vs 테스트 문장 레벨
3) **토크나이저 메타 문제**
   - `tokenizer_config.json`의 `extra_ids` 불일치 가능성

### 교훈
- 문장 레벨 학습으로 반드시 전환 필요
- 체크포인트 업로드/경로 검증 프로세스 필요

---

## V2

### 목표
- V1 실패 요인 제거
- Train/Test 스타일 차이를 정규화로 흡수
- 문장 레벨 데이터로 학습

### 주요 시도
- **정규화 모듈 통합**
  - diacritics/특수문자를 ASCII로 통일
  - OCR 아티팩트(„ 등) 정리

- **데이터 재구성**
  - `data/v2/` 기반 파이프라인 구축
  - 문장 레벨 데이터 생성:
    - `v2_sentence_train.csv` (2,112)
    - `v2_sentence_val.csv` (238)
  - 증강 데이터 정제:
    - `v2_train_augmented_clean.csv` 생성
    - 길이 비율/`<gap>`/`<unk>` 과다 케이스 제거

- **학습 안정화**
  - FP16 비활성화
  - max_len 256으로 축소
  - learning rate 1e-4로 안정화
  - gradient clipping 추가

### 결과
- **Public score: 11.8**
- V1 대비 의미 있는 개선 확인

### 남은 한계
- 문장 레벨 데이터 규모가 여전히 작음
- publications 기반 확장 데이터가 아직 본격적으로 반영되지 않음

### 교훈
- **문장 레벨 + 정규화 통일**이 가장 큰 개선 포인트
- 수치 안정성(FP16, 길이, LR) 영향이 매우 큼

---

## 다음 단계(비계획, 기록용 메모)
- publications 기반 데이터 확장 시도 예정
- 문장 레벨 중심 유지, doc‑level은 보조로만 활용
